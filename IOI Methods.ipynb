{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('l1.json', 'r') as f:\n",
    "    l1_dict=json.load(f)\n",
    "l1=list(l1_dict.keys())\n",
    "neg_adj=list(l1_dict.values())\n",
    "with open('l2.json', 'r') as f:\n",
    "    l2_dict=json.load(f)\n",
    "l2=list(l2_dict.keys())\n",
    "with open('l3.json', 'r') as f:\n",
    "    l3_dict=json.load(f)\n",
    "l3=list(l3_dict.keys())\n",
    "pos_adj=list(l3_dict.values())\n",
    "with open('l4.json', 'r') as f:\n",
    "    l4_dict=json.load(f)\n",
    "l4=list(l4_dict.keys())\n",
    "with open('l5.json', 'r') as f:\n",
    "    l5_dict=json.load(f)\n",
    "l5=list(l5_dict.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting everything up for Trasnformer lens library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook - intended for development only!\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55566/1326878066.py:9: DeprecationWarning:\n",
      "\n",
      "`magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "\n",
      "/tmp/ipykernel_55566/1326878066.py:10: DeprecationWarning:\n",
      "\n",
      "`magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: d5557f85-ee9d-4292-ba4f-414d0533f9b3)')' thrown while requesting HEAD https://huggingface.co/gpt2/resolve/main/config.json\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Clean string 0 <|endoftext|>The day is bright but the night is\n"
     ]
    }
   ],
   "source": [
    "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
    "import plotly.io as pio\n",
    "DEBUG_MODE = False\n",
    "IN_COLAB = False\n",
    "print(\"Running as a Jupyter notebook - intended for development only!\")\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "# Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "ipython.magic(\"load_ext autoreload\")\n",
    "ipython.magic(\"autoreload 2\")\n",
    "\n",
    "pio.renderers.default = \"vscode\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.notebook as tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "from jaxtyping import Float, Int\n",
    "\n",
    "from typing import List, Union, Optional\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "torch.set_grad_enabled(False)\n",
    "from neel_plotly import line, imshow, scatter\n",
    "import transformer_lens.patching as patching\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\")\n",
    "prompts = ['The day is bright but the night is']\n",
    "not_id=model.to_single_token(\" not\")\n",
    "bright_id=model.to_single_token(\" bright\")\n",
    "clean_tokens = model.to_tokens(prompts)\n",
    "print(\"Clean string 0\", model.to_string(clean_tokens[0]))\n",
    "logits,cache=model.run_with_cache(clean_tokens)\n",
    "id=logits[...,-1,:].argmax()\n",
    "model.to_string(id)\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"vscode\"\n",
    "\n",
    "\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which heads directly write to the output?\n",
    "\n",
    "Which attention heads directly affect the model's output:\n",
    "\n",
    "(The heads writting in the resiudual stream at the END position, in a direction that has high dot product with the logit difference)\n",
    "\n",
    "$W_U$ The unembedding matrix\n",
    "\n",
    "$\\overline{LN}$ the layer norm\n",
    "\n",
    "We search for heads (i,j) such that\n",
    "$$\n",
    "\\lambda_{i,j}:=\\mathbb{E}_{x\\sim \\mathbb{P}_{BS} }[\\langle \\overline{LN} \\circ h_{i,j}(X),W_U[a]-W_U[b]\\rangle]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
